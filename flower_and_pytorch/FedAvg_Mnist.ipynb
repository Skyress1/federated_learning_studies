{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWjEXAGYFWi6",
        "outputId": "5ef07935-2add-4dea-be30-ad550bc31fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "from torchsummary import summary\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics"
      ],
      "metadata": {
        "id": "VdgyZUZrGK6d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
      ],
      "metadata": {
        "id": "dOK8nVGuJq1x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = MNIST(\"./dataset\", train=True, download=True, transform=transform)\n",
        "testset = MNIST(\"./dataset\", train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "NRoID_HNG71c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9217df99-1093-45c7-d0c6-d66da6ae881e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 145466258.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 33269896.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 39616042.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15875440.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RvvKTKHGZw",
        "outputId": "d517ce4f-96ec-45f3-c8ee-b54d5c974bf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 5"
      ],
      "metadata": {
        "id": "k259C09tHZRi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_datasets(trainset, testset):\n",
        "\n",
        "    train_partition_size = len(trainset) // NUM_CLIENTS\n",
        "    train_lengths = [train_partition_size] * NUM_CLIENTS\n",
        "    train_datasets = random_split(trainset, train_lengths, torch.Generator().manual_seed(42))\n",
        "    test_partition_size = len(testset) // NUM_CLIENTS\n",
        "    test_lengths = [test_partition_size] * NUM_CLIENTS\n",
        "    test_datasets = random_split(testset, test_lengths, torch.Generator().manual_seed(42))\n",
        "    \n",
        "    testloaders = []\n",
        "    trainloaders = []\n",
        "    for train_ds, test_ds in zip(train_datasets, test_datasets):\n",
        "        trainloaders.append(DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        testloaders.append(DataLoader(test_ds, batch_size=BATCH_SIZE))\n",
        "    return trainloaders, testloaders\n",
        "\n",
        "trainloaders, testloaders = load_datasets(trainset, testset)"
      ],
      "metadata": {
        "id": "G4EDY8P9Gohy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloaders[0]))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dkVCekEQB_5",
        "outputId": "9d9f941c-bd0d-43aa-fe5d-6bf476d173bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloaders[0]))[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5v2O7lZQcFT",
        "outputId": "158c654c-0220-4321-a9b2-6ddf707db3a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(testloaders[0]))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVgxdyBya1Rr",
        "outputId": "ee628b3b-5326-41f2-b38a-816c361ce6a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(testloaders[0]))[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTaIvE0Oa1YM",
        "outputId": "d0b37784-95b3-4639-830d-0a4bbd3d24fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nxrTarJWLNp1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(Net(), (1,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L6W9ebjNHNp",
        "outputId": "3d337c65-2b88-42fc-cdda-02feca0f33f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 24, 24]             156\n",
            "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
            "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
            "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
            "            Linear-5                  [-1, 120]          30,840\n",
            "            Linear-6                   [-1, 84]          10,164\n",
            "            Linear-7                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 0.17\n",
            "Estimated Total Size (MB): 0.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(), labels.to()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(), labels.to()\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "FeOfVNoYQ1uM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "id": "EyN-w4f3RGQ7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, testloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.testloader)\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "StBUL7iqRxGR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "\n",
        "    net = Net().to()\n",
        "\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    testloader = testloaders[int(cid)]\n",
        "\n",
        "    return FlowerClient(net, trainloader, testloader)"
      ],
      "metadata": {
        "id": "YQDjl9bISqg3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "AvtGnyUAU-NZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  \n",
        "    fraction_evaluate=0.5,  \n",
        "    min_fit_clients=5,  \n",
        "    min_evaluate_clients=1, \n",
        "    min_available_clients=5,  \n",
        "    evaluate_metrics_aggregation_fn= weighted_average,\n",
        ")\n",
        "\n",
        "client_resources = None\n",
        "\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBF1DePBSqkN",
        "outputId": "fae224f4-a406-4388-daf2-4bb6d1a86cb5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-05-26 19:15:36,282 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-05-26 19:15:40,114\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-05-26 19:15:44,805 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3933528883.0, 'memory': 7867057767.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3933528883.0, 'memory': 7867057767.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-05-26 19:15:44,822 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-05-26 19:15:44,853 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=1554)\u001b[0m 2023-05-26 19:15:50.698016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-05-26 19:15:54,315 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-05-26 19:15:54,319 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-05-26 19:15:54,322 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-05-26 19:15:54,325 | server.py:218 | fit_round 1: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 2023-05-26 19:15:57.954498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG flwr 2023-05-26 19:16:29,156 | server.py:232 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 0 failures\n",
            "WARNING flwr 2023-05-26 19:16:29,175 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-05-26 19:16:29,180 | server.py:168 | evaluate_round 1: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 2 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:16:31,802 | server.py:182 | evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:16:31,809 | server.py:218 | fit_round 2: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:17:03,302 | server.py:232 | fit_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:17:03,326 | server.py:168 | evaluate_round 2: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 2 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:17:06,150 | server.py:182 | evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:17:06,155 | server.py:218 | fit_round 3: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:17:40,467 | server.py:232 | fit_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:17:40,496 | server.py:168 | evaluate_round 3: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 2 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:17:43,455 | server.py:182 | evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:17:43,461 | server.py:218 | fit_round 4: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:18:13,652 | server.py:232 | fit_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:18:13,682 | server.py:168 | evaluate_round 4: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 2 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:18:16,551 | server.py:182 | evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:18:16,555 | server.py:218 | fit_round 5: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:18:47,883 | server.py:232 | fit_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-05-26 19:18:47,913 | server.py:168 | evaluate_round 5: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 2 clients (out of 5)\n",
            "DEBUG flwr 2023-05-26 19:18:49,714 | server.py:182 | evaluate_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 2 results and 0 failures\n",
            "INFO flwr 2023-05-26 19:18:49,719 | server.py:147 | FL finished in 175.394844708\n",
            "INFO:flwr:FL finished in 175.394844708\n",
            "INFO flwr 2023-05-26 19:18:49,726 | app.py:218 | app_fit: losses_distributed [(1, 0.005138191957958043), (2, 0.0032432186871301388), (3, 0.002073285826772917), (4, 0.0015551996877184138), (5, 0.0014046929040050602)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.005138191957958043), (2, 0.0032432186871301388), (3, 0.002073285826772917), (4, 0.0015551996877184138), (5, 0.0014046929040050602)]\n",
            "INFO flwr 2023-05-26 19:18:49,728 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-05-26 19:18:49,730 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.9547499999999999), (2, 0.96625), (3, 0.9782500000000001), (4, 0.9852500000000001), (5, 0.987)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.9547499999999999), (2, 0.96625), (3, 0.9782500000000001), (4, 0.9852500000000001), (5, 0.987)]}\n",
            "INFO flwr 2023-05-26 19:18:49,732 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-05-26 19:18:49,734 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.005138191957958043\n",
              "\tround 2: 0.0032432186871301388\n",
              "\tround 3: 0.002073285826772917\n",
              "\tround 4: 0.0015551996877184138\n",
              "\tround 5: 0.0014046929040050602\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.9547499999999999), (2, 0.96625), (3, 0.9782500000000001), (4, 0.9852500000000001), (5, 0.987)]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}
